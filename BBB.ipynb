{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big Brother Brasil 26 - Reaction Analysis Dashboard\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook analyzes **participant reaction data** from Big Brother Brasil 26 (BBB26), using data from the GloboPlay API. Participants react to each other daily using emoji-based reactions, which reveal social dynamics, alliances, and conflicts within the house.\n",
        "\n",
        "### What are Reactions?\n",
        "\n",
        "Every day, BBB participants can give reactions to other houseguests using emojis. These reactions fall into three categories:\n",
        "\n",
        "| Category | Reactions | Meaning |\n",
        "|----------|-----------|---------|\n",
        "| **Positive** ‚ù§Ô∏è | Cora√ß√£o (Heart) | Love, support, friendship |\n",
        "| **Mild Negative** üíºüå±üç™ | Mala (Baggage), Planta (Plant), Biscoito (Cookie) | Annoying, invisible/boring, attention-seeking |\n",
        "| **Strong Negative** üêçüéØü§Æü§•üíî | Cobra (Snake), Alvo (Target), V√¥mito (Vomit), Mentiroso (Liar), Cora√ß√£o Partido (Broken Heart) | Betrayal, enemy, disgust, dishonesty, disappointment |\n",
        "\n",
        "### Key Metrics Analyzed\n",
        "\n",
        "1. **Sentiment Score**: Net positivity (positive reactions minus weighted negatives)\n",
        "2. **Controversy Score**: Product of positive and negative reactions (high = divisive)\n",
        "3. **Balance Correlation**: Relationship between game balance (currency) and social standing\n",
        "4. **Alliance Mapping**: Who supports whom, and mutual relationships\n",
        "\n",
        "### Data Source\n",
        "\n",
        "- **API**: `https://apis-globoplay.globo.com/mve-api/globo-play/realities/bbb/participants/`\n",
        "- **Historical Data**: JSON snapshots saved with timestamps for timeline analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Setup & Configuration\n",
        "\n",
        "Import required libraries for data processing, analysis, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import networkx as nx\n",
        "\n",
        "# Set style for matplotlib\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "    except:\n",
        "        plt.style.use('dark_background')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Reaction Categorization\n",
        "\n",
        "Define the sentiment categories for each reaction type. This categorization is crucial for all analysis.\n",
        "\n",
        "### Why These Categories?\n",
        "\n",
        "- **Positive**: Only the heart emoji represents genuine support\n",
        "- **Mild Negative**: These suggest annoyance but not conflict\n",
        "  - üå± Planta (Plant) = \"You don't do anything, just blend in\"\n",
        "  - üíº Mala (Baggage) = \"You're annoying/a burden\"\n",
        "  - üç™ Biscoito (Cookie) = \"You're just seeking attention\"\n",
        "- **Strong Negative**: These indicate real conflict or betrayal\n",
        "  - üêç Cobra (Snake) = \"You're a backstabber\"\n",
        "  - üéØ Alvo (Target) = \"You're my target/enemy\"\n",
        "  - ü§Æ V√¥mito (Vomit) = \"I'm disgusted by you\"\n",
        "  - ü§• Mentiroso (Liar) = \"You're dishonest\"\n",
        "  - üíî Cora√ß√£o Partido (Broken Heart) = \"You disappointed me\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# REACTION CATEGORIES & EMOJI MAPPING\n",
        "# ============================================================================\n",
        "\n",
        "# Emoji mapping for display\n",
        "EMOJI_MAP = {\n",
        "    'Cora√ß√£o': '‚ù§Ô∏è',\n",
        "    'Cora√ß√£o partido': 'üíî',\n",
        "    'Cobra': 'üêç',\n",
        "    'Mala': 'üíº',\n",
        "    'Planta': 'üå±',\n",
        "    'Biscoito': 'üç™',\n",
        "    'Alvo': 'üéØ',\n",
        "    'V√¥mito': 'ü§Æ',\n",
        "    'Mentiroso': 'ü§•'\n",
        "}\n",
        "\n",
        "# Sentiment categories\n",
        "POSITIVE_REACTIONS = ['Cora√ß√£o']\n",
        "MILD_NEGATIVE_REACTIONS = ['Planta', 'Mala', 'Biscoito']\n",
        "STRONG_NEGATIVE_REACTIONS = ['Cobra', 'Alvo', 'V√¥mito', 'Mentiroso', 'Cora√ß√£o partido']\n",
        "\n",
        "# Sentiment weights for scoring\n",
        "SENTIMENT_WEIGHTS = {\n",
        "    'positive': 1.0,      # Full positive weight\n",
        "    'mild_negative': -0.5,  # Half negative weight (less severe)\n",
        "    'strong_negative': -1.0  # Full negative weight\n",
        "}\n",
        "\n",
        "def get_reaction_emoji(reaction_name):\n",
        "    \"\"\"Return emoji for a Portuguese reaction name\"\"\"\n",
        "    return EMOJI_MAP.get(reaction_name, reaction_name)\n",
        "\n",
        "def categorize_reaction(reaction_name):\n",
        "    \"\"\"Categorize a reaction into sentiment categories\"\"\"\n",
        "    if reaction_name in POSITIVE_REACTIONS:\n",
        "        return 'positive'\n",
        "    elif reaction_name in MILD_NEGATIVE_REACTIONS:\n",
        "        return 'mild_negative'\n",
        "    elif reaction_name in STRONG_NEGATIVE_REACTIONS:\n",
        "        return 'strong_negative'\n",
        "    return 'unknown'\n",
        "\n",
        "def get_sentiment_weight(reaction_name):\n",
        "    \"\"\"Get numerical sentiment weight for a reaction\"\"\"\n",
        "    category = categorize_reaction(reaction_name)\n",
        "    return SENTIMENT_WEIGHTS.get(category, 0)\n",
        "\n",
        "print(\"‚úÖ Reaction categories configured:\")\n",
        "print(f\"   Positive: {[f'{r} {get_reaction_emoji(r)}' for r in POSITIVE_REACTIONS]}\")\n",
        "print(f\"   Mild Negative: {[f'{r} {get_reaction_emoji(r)}' for r in MILD_NEGATIVE_REACTIONS]}\")\n",
        "print(f\"   Strong Negative: {[f'{r} {get_reaction_emoji(r)}' for r in STRONG_NEGATIVE_REACTIONS]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Data Collection\n",
        "\n",
        "Functions to fetch data from the GloboPlay API and manage local backups.\n",
        "\n",
        "### Data Flow\n",
        "\n",
        "1. **Primary**: Fetch fresh data from API\n",
        "2. **Backup**: Save timestamped JSON files locally  \n",
        "3. **Fallback**: Load most recent local file if API fails\n",
        "\n",
        "### Historical Data\n",
        "\n",
        "Each run saves a new JSON file with timestamp, enabling timeline analysis of how reactions change over the season."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DATA COLLECTION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "API_URL = \"https://apis-globoplay.globo.com/mve-api/globo-play/realities/bbb/participants/\"\n",
        "\n",
        "def save_api_response(api_url=API_URL):\n",
        "    \"\"\"Fetch data from API and save with timestamp\"\"\"\n",
        "    try:\n",
        "        response = requests.get(api_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        # Save with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        filename = f\"bbb_participants_{timestamp}.json\"\n",
        "        \n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        print(f\"‚úÖ Data saved to {filename}\")\n",
        "        print(f\"   Participants found: {len(data)}\")\n",
        "        return data\n",
        "        \n",
        "    except requests.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è API request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_latest_saved_data():\n",
        "    \"\"\"Load the most recent saved JSON file as fallback\"\"\"\n",
        "    json_files = sorted(glob.glob(\"bbb_participants_*.json\"))\n",
        "    \n",
        "    if not json_files:\n",
        "        print(\"‚ùå No saved data files found\")\n",
        "        return None\n",
        "    \n",
        "    latest_file = json_files[-1]\n",
        "    print(f\"üìÇ Loading: {latest_file}\")\n",
        "    \n",
        "    with open(latest_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f\"   Participants loaded: {len(data)}\")\n",
        "    return data\n",
        "\n",
        "def get_all_reaction_types(data):\n",
        "    \"\"\"Extract all unique reaction types from data\"\"\"\n",
        "    reactions = set()\n",
        "    for participant in data:\n",
        "        received = participant.get('characteristics', {}).get('receivedReactions', [])\n",
        "        for reaction in received:\n",
        "            if label := reaction.get('label'):\n",
        "                reactions.add(label)\n",
        "    return sorted(reactions)\n",
        "\n",
        "print(\"‚úÖ Data collection functions ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Data Processing\n",
        "\n",
        "Transform raw API data into structured formats for analysis.\n",
        "\n",
        "### Data Structures Created\n",
        "\n",
        "1. **organized_data**: List of processed participant dictionaries\n",
        "2. **cross_table**: Pandas DataFrame showing reaction counts between all pairs\n",
        "3. **sentiment_matrix**: Numerical sentiment scores between participants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DATA PROCESSING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def process_participants(data, verbose=False):\n",
        "    \"\"\"Process raw API data into organized participant list\n",
        "    \n",
        "    Returns:\n",
        "        List of dicts with participant info and their received reactions\n",
        "    \"\"\"\n",
        "    if not data:\n",
        "        print(\"‚ùå No data to process\")\n",
        "        return []\n",
        "\n",
        "    organized_data = []\n",
        "\n",
        "    for participant in data:\n",
        "        chars = participant.get('characteristics', {})\n",
        "        \n",
        "        participant_data = {\n",
        "            \"name\": participant.get('name', 'N/A'),\n",
        "            \"job\": chars.get('job', 'N/A'),\n",
        "            \"group\": chars.get('group', 'N/A'),        # Vip or Xepa\n",
        "            \"memberOf\": chars.get('memberOf', 'N/A'),  # Camarote, Pipoca, Veterano\n",
        "            \"balance\": chars.get('balance', 0),\n",
        "            \"eliminated\": chars.get('eliminated', False),\n",
        "            \"roles\": [role.get('label', 'N/A') for role in chars.get('roles', [])],\n",
        "            \"reactions\": {},\n",
        "            \"total_reactions\": 0,\n",
        "            \"duo_partner\": (participant.get('duo') or {}).get('name', 'None')\n",
        "        }\n",
        "\n",
        "        # Process received reactions\n",
        "        received_reactions = chars.get('receivedReactions', [])\n",
        "        for reaction in received_reactions:\n",
        "            label = reaction.get('label')\n",
        "            amount = reaction.get('amount', 0)\n",
        "            givers = [p.get('name') for p in reaction.get('participants', [])]\n",
        "            \n",
        "            participant_data['reactions'][label] = {\n",
        "                'amount': amount,\n",
        "                'givers': givers\n",
        "            }\n",
        "            participant_data['total_reactions'] += amount\n",
        "        \n",
        "        organized_data.append(participant_data)\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"{participant_data['name']}: {participant_data['total_reactions']} reactions\")\n",
        "\n",
        "    print(f\"‚úÖ Processed {len(organized_data)} participants\")\n",
        "    return organized_data\n",
        "\n",
        "def create_cross_table(organized_data):\n",
        "    \"\"\"Create reaction matrix: who reacted to whom\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with givers as rows, receivers as columns\n",
        "    \"\"\"\n",
        "    # Get all unique names\n",
        "    all_names = set()\n",
        "    for p in organized_data:\n",
        "        all_names.add(p['name'])\n",
        "        for reaction_data in p['reactions'].values():\n",
        "            all_names.update(reaction_data['givers'])\n",
        "    \n",
        "    all_names = sorted(all_names)\n",
        "    \n",
        "    # Initialize matrix\n",
        "    matrix = pd.DataFrame(0, index=all_names, columns=all_names)\n",
        "    \n",
        "    # Fill in reactions\n",
        "    for p in organized_data:\n",
        "        receiver = p['name']\n",
        "        for reaction_name, reaction_data in p['reactions'].items():\n",
        "            for giver in reaction_data['givers']:\n",
        "                if giver in matrix.index and receiver in matrix.columns:\n",
        "                    matrix.loc[giver, receiver] += 1\n",
        "    \n",
        "    print(f\"‚úÖ Cross table created: {len(all_names)}x{len(all_names)}\")\n",
        "    return matrix\n",
        "\n",
        "def create_sentiment_matrix(organized_data):\n",
        "    \"\"\"Create weighted sentiment matrix\n",
        "    \n",
        "    Positive reactions = +1, Mild negative = -0.5, Strong negative = -1\n",
        "    \"\"\"\n",
        "    all_names = sorted(set(p['name'] for p in organized_data))\n",
        "    matrix = pd.DataFrame(0.0, index=all_names, columns=all_names)\n",
        "    \n",
        "    for p in organized_data:\n",
        "        receiver = p['name']\n",
        "        for reaction_name, reaction_data in p['reactions'].items():\n",
        "            weight = get_sentiment_weight(reaction_name)\n",
        "            for giver in reaction_data['givers']:\n",
        "                if giver in matrix.index:\n",
        "                    matrix.loc[giver, receiver] += weight\n",
        "    \n",
        "    return matrix\n",
        "\n",
        "print(\"‚úÖ Data processing functions ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Analysis Functions\n",
        "\n",
        "Calculate metrics and generate insights from the reaction data.\n",
        "\n",
        "### Key Metrics\n",
        "\n",
        "| Metric | Formula | Meaning |\n",
        "|--------|---------|---------|\n",
        "| **Sentiment Score** | positive - 0.5√ómild - 1√óstrong | Net positivity received |\n",
        "| **Controversy Score** | positive √ó (mild + strong) | How divisive someone is |\n",
        "| **Positive %** | positive / total √ó 100 | % of reactions that are positive |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ANALYSIS FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_reactions(organized_data):\n",
        "    \"\"\"Calculate reaction statistics for each participant\"\"\"\n",
        "    analysis = {}\n",
        "    \n",
        "    for p in organized_data:\n",
        "        name = p['name']\n",
        "        total = p.get('total_reactions', 0)\n",
        "        \n",
        "        positive = 0\n",
        "        mild_negative = 0\n",
        "        strong_negative = 0\n",
        "        \n",
        "        for reaction_name, data in p['reactions'].items():\n",
        "            amount = data.get('amount', 0)\n",
        "            category = categorize_reaction(reaction_name)\n",
        "            \n",
        "            if category == 'positive':\n",
        "                positive += amount\n",
        "            elif category == 'mild_negative':\n",
        "                mild_negative += amount\n",
        "            elif category == 'strong_negative':\n",
        "                strong_negative += amount\n",
        "        \n",
        "        # Calculate metrics\n",
        "        sentiment = positive - 0.5*mild_negative - strong_negative\n",
        "        controversy = positive * (mild_negative + strong_negative)\n",
        "        \n",
        "        analysis[name] = {\n",
        "            'total': total,\n",
        "            'positive': positive,\n",
        "            'mild_negative': mild_negative,\n",
        "            'strong_negative': strong_negative,\n",
        "            'positive_pct': (positive / total * 100) if total > 0 else 0,\n",
        "            'sentiment_score': sentiment,\n",
        "            'controversy_score': controversy,\n",
        "            'balance': p.get('balance', 0),\n",
        "            'group': p.get('group', 'N/A'),\n",
        "            'memberOf': p.get('memberOf', 'N/A')\n",
        "        }\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "def find_alliances_and_enemies(organized_data):\n",
        "    \"\"\"Identify mutual relationships between participants\"\"\"\n",
        "    sentiment_given = defaultdict(lambda: defaultdict(float))\n",
        "    \n",
        "    for p in organized_data:\n",
        "        receiver = p['name']\n",
        "        for reaction_name, data in p['reactions'].items():\n",
        "            weight = get_sentiment_weight(reaction_name)\n",
        "            for giver in data['givers']:\n",
        "                sentiment_given[giver][receiver] += weight\n",
        "    \n",
        "    # Find mutual relationships\n",
        "    relationships = []\n",
        "    names = sorted(set(p['name'] for p in organized_data))\n",
        "    checked = set()\n",
        "    \n",
        "    for p1 in names:\n",
        "        for p2 in names:\n",
        "            if p1 < p2 and (p1, p2) not in checked:\n",
        "                checked.add((p1, p2))\n",
        "                s1_to_2 = sentiment_given[p1].get(p2, 0)\n",
        "                s2_to_1 = sentiment_given[p2].get(p1, 0)\n",
        "                \n",
        "                if s1_to_2 != 0 or s2_to_1 != 0:\n",
        "                    if s1_to_2 > 0 and s2_to_1 > 0:\n",
        "                        rel_type = 'Allies'\n",
        "                    elif s1_to_2 < 0 and s2_to_1 < 0:\n",
        "                        rel_type = 'Enemies'\n",
        "                    else:\n",
        "                        rel_type = 'Mixed'\n",
        "                    \n",
        "                    relationships.append({\n",
        "                        'person1': p1,\n",
        "                        'person2': p2,\n",
        "                        'p1_to_p2': s1_to_2,\n",
        "                        'p2_to_p1': s2_to_1,\n",
        "                        'mutual_sentiment': s1_to_2 + s2_to_1,\n",
        "                        'relationship': rel_type\n",
        "                    })\n",
        "    \n",
        "    return pd.DataFrame(relationships)\n",
        "\n",
        "def print_analysis_report(analysis):\n",
        "    \"\"\"Print comprehensive analysis report\"\"\"\n",
        "    df = pd.DataFrame(analysis).T\n",
        "    df = df.sort_values('sentiment_score', ascending=False)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä REACTION ANALYSIS REPORT\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(\"\\nüèÜ TOP 5 - Most Loved (Highest Sentiment):\")\n",
        "    print(\"-\"*50)\n",
        "    for name in df.head(5).index:\n",
        "        data = analysis[name]\n",
        "        print(f\"  {name}: {data['sentiment_score']:.1f} ({data['positive_pct']:.0f}% positive)\")\n",
        "    \n",
        "    print(\"\\n‚ö†Ô∏è BOTTOM 5 - Most Targeted (Lowest Sentiment):\")\n",
        "    print(\"-\"*50)\n",
        "    for name in df.tail(5).index:\n",
        "        data = analysis[name]\n",
        "        print(f\"  {name}: {data['sentiment_score']:.1f} ({data['positive_pct']:.0f}% positive)\")\n",
        "    \n",
        "    print(\"\\nüé≠ TOP 5 - Most Controversial (Divisive):\")\n",
        "    print(\"-\"*50)\n",
        "    controversial = df.nlargest(5, 'controversy_score')\n",
        "    for name in controversial.index:\n",
        "        data = analysis[name]\n",
        "        print(f\"  {name}: controversy={data['controversy_score']:.0f} (‚ù§Ô∏è{data['positive']} vs üëé{data['mild_negative']+data['strong_negative']})\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "print(\"‚úÖ Analysis functions ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Visualizations\n",
        "\n",
        "Create charts and graphs to visualize reaction patterns.\n",
        "\n",
        "### Visualizations Generated\n",
        "\n",
        "1. **Sentiment Heatmap**: Color-coded matrix of who likes/dislikes whom\n",
        "2. **Balance Correlation**: Scatter plot of game balance vs sentiment\n",
        "3. **Timeline Analysis**: How reactions change over time (using historical data)\n",
        "4. **Network Graph**: Visual network of relationships\n",
        "5. **Analysis Dashboard**: Multi-panel summary charts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def create_sentiment_heatmap(organized_data, figsize=(14, 12)):\n",
        "    \"\"\"Create heatmap showing sentiment between all participants\"\"\"\n",
        "    sentiment_matrix = create_sentiment_matrix(organized_data)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    # Create custom colormap (red for negative, white for neutral, green for positive)\n",
        "    cmap = sns.diverging_palette(10, 130, as_cmap=True)\n",
        "    \n",
        "    sns.heatmap(\n",
        "        sentiment_matrix,\n",
        "        annot=True,\n",
        "        fmt='.1f',\n",
        "        cmap=cmap,\n",
        "        center=0,\n",
        "        linewidths=0.5,\n",
        "        square=True,\n",
        "        cbar_kws={'label': 'Sentiment (+ = positive, - = negative)'}\n",
        "    )\n",
        "    \n",
        "    plt.title('Reaction Sentiment Matrix\\n(Rows = Giver, Columns = Receiver)', fontsize=14)\n",
        "    plt.xlabel('Received Reactions From')\n",
        "    plt.ylabel('Gave Reactions To')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"reaction_heatmap_{timestamp}.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "    print(f\"üìä Saved: {filename}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def create_balance_correlation(organized_data, analysis):\n",
        "    \"\"\"Scatter plot: Game balance vs Sentiment score\"\"\"\n",
        "    data = []\n",
        "    for p in organized_data:\n",
        "        name = p['name']\n",
        "        if name in analysis:\n",
        "            data.append({\n",
        "                'name': name,\n",
        "                'balance': p.get('balance', 0),\n",
        "                'sentiment': analysis[name]['sentiment_score'],\n",
        "                'group': p.get('group', 'Unknown'),\n",
        "                'type': p.get('memberOf', 'Unknown')\n",
        "            })\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # Plot by group (Vip/Xepa)\n",
        "    colors_group = {'Vip': '#FFD700', 'Xepa': '#87CEEB'}\n",
        "    for group in df['group'].unique():\n",
        "        mask = df['group'] == group\n",
        "        axes[0].scatter(\n",
        "            df[mask]['balance'], \n",
        "            df[mask]['sentiment'],\n",
        "            c=colors_group.get(group, 'gray'),\n",
        "            label=group,\n",
        "            s=100,\n",
        "            alpha=0.7\n",
        "        )\n",
        "    \n",
        "    # Add labels\n",
        "    for _, row in df.iterrows():\n",
        "        axes[0].annotate(\n",
        "            row['name'].split()[0],  # First name only\n",
        "            (row['balance'], row['sentiment']),\n",
        "            fontsize=8,\n",
        "            alpha=0.7\n",
        "        )\n",
        "    \n",
        "    axes[0].set_xlabel('Game Balance (BBBs)')\n",
        "    axes[0].set_ylabel('Sentiment Score')\n",
        "    axes[0].set_title('Balance vs Sentiment by Group')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot by type (Camarote/Pipoca/Veterano)\n",
        "    colors_type = {'Camarote': '#9B59B6', 'Pipoca': '#E74C3C', 'Veterano': '#2ECC71'}\n",
        "    for ptype in df['type'].unique():\n",
        "        mask = df['type'] == ptype\n",
        "        axes[1].scatter(\n",
        "            df[mask]['balance'], \n",
        "            df[mask]['sentiment'],\n",
        "            c=colors_type.get(ptype, 'gray'),\n",
        "            label=ptype,\n",
        "            s=100,\n",
        "            alpha=0.7\n",
        "        )\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        axes[1].annotate(\n",
        "            row['name'].split()[0],\n",
        "            (row['balance'], row['sentiment']),\n",
        "            fontsize=8,\n",
        "            alpha=0.7\n",
        "        )\n",
        "    \n",
        "    axes[1].set_xlabel('Game Balance (BBBs)')\n",
        "    axes[1].set_ylabel('Sentiment Score')\n",
        "    axes[1].set_title('Balance vs Sentiment by Type')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"balance_correlation_{timestamp}.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "    print(f\"üìä Saved: {filename}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate correlation\n",
        "    corr = df['balance'].corr(df['sentiment'])\n",
        "    print(f\"\\nüìà Correlation (Balance vs Sentiment): {corr:.3f}\")\n",
        "\n",
        "print(\"‚úÖ Visualization functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_reaction_network(organized_data, min_sentiment=0.5):\n",
        "    \"\"\"Create network graph of relationships\"\"\"\n",
        "    import networkx as nx\n",
        "    \n",
        "    sentiment_matrix = create_sentiment_matrix(organized_data)\n",
        "    \n",
        "    G = nx.DiGraph()\n",
        "    \n",
        "    # Add nodes\n",
        "    for p in organized_data:\n",
        "        G.add_node(p['name'], \n",
        "                   group=p.get('group', 'Unknown'),\n",
        "                   balance=p.get('balance', 0))\n",
        "    \n",
        "    # Add edges for significant relationships\n",
        "    for giver in sentiment_matrix.index:\n",
        "        for receiver in sentiment_matrix.columns:\n",
        "            if giver != receiver:\n",
        "                sentiment = sentiment_matrix.loc[giver, receiver]\n",
        "                if abs(sentiment) >= min_sentiment:\n",
        "                    G.add_edge(giver, receiver, \n",
        "                              weight=abs(sentiment),\n",
        "                              sentiment=sentiment)\n",
        "    \n",
        "    plt.figure(figsize=(16, 12))\n",
        "    \n",
        "    # Position nodes\n",
        "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
        "    \n",
        "    # Color nodes by group\n",
        "    node_colors = ['#FFD700' if G.nodes[n].get('group') == 'Vip' else '#87CEEB' \n",
        "                   for n in G.nodes()]\n",
        "    \n",
        "    # Draw nodes\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, \n",
        "                           node_size=1500, alpha=0.8)\n",
        "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "    \n",
        "    # Draw edges - green for positive, red for negative\n",
        "    positive_edges = [(u, v) for u, v, d in G.edges(data=True) if d['sentiment'] > 0]\n",
        "    negative_edges = [(u, v) for u, v, d in G.edges(data=True) if d['sentiment'] < 0]\n",
        "    \n",
        "    nx.draw_networkx_edges(G, pos, edgelist=positive_edges,\n",
        "                           edge_color='green', alpha=0.5, \n",
        "                           arrows=True, arrowsize=15)\n",
        "    nx.draw_networkx_edges(G, pos, edgelist=negative_edges,\n",
        "                           edge_color='red', alpha=0.5, \n",
        "                           arrows=True, arrowsize=15)\n",
        "    \n",
        "    plt.title('Reaction Network\\n(Green = Positive, Red = Negative)', fontsize=14)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"reaction_network_{timestamp}.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "    print(f\"üìä Saved: {filename}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def analyze_reaction_timeline():\n",
        "    \"\"\"Analyze how reactions change over time using saved JSON files\"\"\"\n",
        "    json_files = sorted(glob.glob(\"bbb_participants_*.json\"))\n",
        "    \n",
        "    if len(json_files) < 2:\n",
        "        print(\"‚ö†Ô∏è Need at least 2 data files for timeline analysis\")\n",
        "        return\n",
        "    \n",
        "    # Get unique dates (deduplicate same-day multiple runs)\n",
        "    daily_files = {}\n",
        "    for f in json_files:\n",
        "        date = f.split('_')[2]  # Extract date from filename\n",
        "        daily_files[date] = f  # Keep latest file per day\n",
        "    \n",
        "    print(f\"üìÖ Found {len(daily_files)} unique days of data\")\n",
        "    \n",
        "    timeline_data = []\n",
        "    \n",
        "    for date, filepath in sorted(daily_files.items()):\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        for p in data:\n",
        "            name = p['name']\n",
        "            chars = p.get('characteristics', {})\n",
        "            received = chars.get('receivedReactions', [])\n",
        "            \n",
        "            pos = sum(r['amount'] for r in received if r['label'] in POSITIVE_REACTIONS)\n",
        "            neg = sum(r['amount'] for r in received if r['label'] in MILD_NEGATIVE_REACTIONS + STRONG_NEGATIVE_REACTIONS)\n",
        "            \n",
        "            timeline_data.append({\n",
        "                'date': date,\n",
        "                'name': name,\n",
        "                'positive': pos,\n",
        "                'negative': neg,\n",
        "                'sentiment': pos - neg\n",
        "            })\n",
        "    \n",
        "    df = pd.DataFrame(timeline_data)\n",
        "    \n",
        "    # Plot sentiment over time for top/bottom participants\n",
        "    latest_analysis = df[df['date'] == max(df['date'])]\n",
        "    top_5 = latest_analysis.nlargest(5, 'sentiment')['name'].tolist()\n",
        "    bottom_5 = latest_analysis.nsmallest(5, 'sentiment')['name'].tolist()\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "    \n",
        "    for name in top_5:\n",
        "        person_data = df[df['name'] == name].sort_values('date')\n",
        "        axes[0].plot(person_data['date'], person_data['sentiment'], \n",
        "                    marker='o', label=name)\n",
        "    \n",
        "    axes[0].set_title('Sentiment Over Time - Most Loved')\n",
        "    axes[0].legend(bbox_to_anchor=(1.05, 1))\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    for name in bottom_5:\n",
        "        person_data = df[df['name'] == name].sort_values('date')\n",
        "        axes[1].plot(person_data['date'], person_data['sentiment'], \n",
        "                    marker='o', label=name)\n",
        "    \n",
        "    axes[1].set_title('Sentiment Over Time - Most Targeted')\n",
        "    axes[1].legend(bbox_to_anchor=(1.05, 1))\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"reaction_timeline_{timestamp}.png\"\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "    print(f\"üìä Saved: {filename}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úÖ Additional visualization functions ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Main Execution\n",
        "\n",
        "Run the complete analysis pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main analysis pipeline\"\"\"\n",
        "    \n",
        "    # 1. Fetch or load data\n",
        "    print(\"=\"*70)\n",
        "    print(\"üì• LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    data = save_api_response()\n",
        "    \n",
        "    if not data:\n",
        "        print(\"\\n‚ö†Ô∏è API failed, using saved data...\")\n",
        "        data = load_latest_saved_data()\n",
        "    \n",
        "    if not data:\n",
        "        print(\"‚ùå No data available\")\n",
        "        return\n",
        "    \n",
        "    # 2. Show reaction types\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üé≠ REACTION TYPES FOUND\")\n",
        "    print(\"=\"*70)\n",
        "    for reaction in get_all_reaction_types(data):\n",
        "        emoji = get_reaction_emoji(reaction)\n",
        "        category = categorize_reaction(reaction)\n",
        "        print(f\"  {emoji} {reaction} ‚Üí {category}\")\n",
        "    \n",
        "    # 3. Process data\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚öôÔ∏è PROCESSING DATA\")\n",
        "    print(\"=\"*70)\n",
        "    organized_data = process_participants(data)\n",
        "    cross_table = create_cross_table(organized_data)\n",
        "    \n",
        "    # 4. Analysis\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üîç RUNNING ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    analysis = analyze_reactions(organized_data)\n",
        "    df_analysis = print_analysis_report(analysis)\n",
        "    \n",
        "    # 5. Find relationships\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ü§ù RELATIONSHIP ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    relationships = find_alliances_and_enemies(organized_data)\n",
        "    \n",
        "    if not relationships.empty:\n",
        "        print(\"\\nTop Mutual Allies:\")\n",
        "        allies = relationships[relationships['relationship'] == 'Allies'].nlargest(10, 'mutual_sentiment')\n",
        "        for _, row in allies.iterrows():\n",
        "            print(f\"  ‚ù§Ô∏è {row['person1']} <-> {row['person2']}: {row['mutual_sentiment']:.1f}\")\n",
        "        \n",
        "        print(\"\\nTop Mutual Enemies:\")\n",
        "        enemies = relationships[relationships['relationship'] == 'Enemies'].nsmallest(5, 'mutual_sentiment')\n",
        "        for _, row in enemies.iterrows():\n",
        "            print(f\"  ‚öîÔ∏è {row['person1']} <-> {row['person2']}: {row['mutual_sentiment']:.1f}\")\n",
        "    \n",
        "    # 6. Visualizations\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä CREATING VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    create_sentiment_heatmap(organized_data)\n",
        "    create_balance_correlation(organized_data, analysis)\n",
        "    create_reaction_network(organized_data)\n",
        "    analyze_reaction_timeline()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ ANALYSIS COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    return organized_data, analysis, cross_table, relationships\n",
        "\n",
        "# Run the analysis\n",
        "organized_data, analysis, cross_table, relationships = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Cross Table View\n",
        "\n",
        "Display the full reaction cross-table showing all participant interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the cross table\n",
        "print(\"\\nüìã REACTION CROSS TABLE\")\n",
        "print(\"Rows = Who gave reactions, Columns = Who received them\")\n",
        "print(\"=\"*70)\n",
        "display(cross_table)\n",
        "\n",
        "# Save cross table to CSV\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "csv_filename = f\"reaction_cross_table_{timestamp}.csv\"\n",
        "cross_table.to_csv(csv_filename)\n",
        "print(f\"\\nüíæ Cross table saved to: {csv_filename}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
